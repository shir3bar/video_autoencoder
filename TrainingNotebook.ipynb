{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Net import Net\n",
    "from AuxiliaryFunctions import save_checkpoint, save_recon, fig_to_img\n",
    "from VideoDataset import VideoDataset\n",
    "from VideoTransforms import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,loader,device, num_epochs,dir, batch_size=4, learning_rate=1e-3,model_name='model',checkpoint=[]):\n",
    "    torch.manual_seed(42)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-3, weight_decay=1e-5)\n",
    "    start_idx = 0\n",
    "    if isinstance(checkpoint,dict):\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_idx = checkpoint['epoch']\n",
    "    for epoch in range(start_idx,num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            clips = data['clip'].to(device)\n",
    "            reconstruction = model(clips)\n",
    "            loss = criterion(clips,reconstruction)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()*clips.size(0)\n",
    "            if i % 1000 == 0:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, loss.item()))\n",
    "        \n",
    "        save_checkpoint(model,optimizer,epoch,running_loss,name=model_name)\n",
    "        print(running_loss)\n",
    "        save_recon(reconstruction,model_name,epoch,dir)\n",
    "    return running_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory='/Volumes/GoogleDrive/My Drive/PhD/cut_swim_samples'\n",
    "ds=VideoDataset(directory,num_frames=20, \n",
    "                transform=transforms.Compose([Rescale(256),ToTensor()]),swim_sample=False)\n",
    "dataloader = DataLoader(ds, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 20, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['clip'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(color_channels=1)\n",
    "model.to(device)\n",
    "start = timer()\n",
    "run_loss=train(model,dataloader,device,num_epochs=150,dir=dir,model_name='model_091120_20frms',checkpoint=checkpoint)\n",
    "end = timer()\n",
    "print(f'elapsed training time {end-start} sec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
